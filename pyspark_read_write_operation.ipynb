{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "@Author: Naveen Madev Naik<br>\n",
    "@Date: 2024-08-08<br>\n",
    "@Last Modified by: Naveen Madev Naik<br>\n",
    "@Last Modified time: 2024-08-08<br>\n",
    "@Title: Read write operation on textinput format files using pyspark<br>\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the Spark Session\n",
    "spark=SparkSession.builder\\\n",
    "        .appName(\"Read Write operation on inputformat files\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Read and Writing csv file using pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+------+----------------------+\n",
      "|Year|Industry_aggregation_NZSIOC|Industry_code_NZSIOC|Industry_name_NZSIOC|             Units|Variable_code|       Variable_name|   Variable_category| Value|Industry_code_ANZSIC06|\n",
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+------+----------------------+\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H01|        Total income|Financial perform...|930995|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H04|Sales, government...|Financial perform...|821630|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H05|Interest, dividen...|Financial perform...| 84354|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H07|Non-operating income|Financial perform...| 25010|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H08|   Total expenditure|Financial perform...|832964|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H09|Interest and dona...|Financial perform...| 55267|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H10|      Indirect taxes|Financial perform...|  7426|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H11|        Depreciation|Financial perform...| 30814|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H12|Salaries and wage...|Financial perform...|147663|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H13|Redundancy and se...|Financial perform...|   269|  ANZSIC06 division...|\n",
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_filePath =\"file:///C:/Users/naikn/OneDrive/Documents/python/Spark/new.csv\"\n",
    "df_csv = spark.read.csv(csv_filePath, header=True)\n",
    "\n",
    "# Show the DataFrame\n",
    "df_csv.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to CSV\n",
    "df_csv.write.csv(\"file:///C:/Users/naikn/OneDrive/Documents/python/Spark/output.csv\",)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Read and Writing in JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----+----+----------+\n",
      "|_corrupt_record| age|  id|      name|\n",
      "+---------------+----+----+----------+\n",
      "|              [|NULL|NULL|      NULL|\n",
      "|           NULL|  30|   1|  John Doe|\n",
      "|           NULL|NULL|   2|Jane Smith|\n",
      "|           NULL|  25| abc|Invalid ID|\n",
      "|           NULL|  28|   3|     Alice|\n",
      "|              ]|NULL|NULL|      NULL|\n",
      "+---------------+----+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_json=spark.read.json(\"file:///C:/Users/naikn/OneDrive/Documents/python/Spark/sample_file.json\")\n",
    "df_json.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv.write.json(\"file:///C:/Users/naikn/OneDrive/Documents/python/Spark/example.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Reading and writing text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text=spark.read.text(\"file:///C:/Users/naikn/OneDrive/Documents/python/Spark/sample.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text.write.text(\"file:///C:/Users/naikn/OneDrive/Documents/python/Spark/output.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Reading CSV file and writing in text and json fromat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = r\"file:///C:/Users/naikn/OneDrive/Documents/python/Spark/new.csv\"\n",
    "df_csv = spark.read.option(\"header\", True).csv(csv_file_path,inferSchema=True)\n",
    "\n",
    "# Writing the DataFrame to a JSON file\n",
    "json_file_path = \"file:///C:/Users/naikn/OneDrive/Documents/python/Spark/outputfile.json\"\n",
    "df_csv.write.json(json_file_path,mode=\"overwrite\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting json string\n",
    "df_json_strings = df_csv.toJSON()\n",
    "\n",
    "#json string to text file\n",
    "text_file_path = \"file:///C:/Users/naikn/OneDrive/Documents/python/Spark/outputfile.json.txt\"\n",
    "df_json_strings.saveAsTextFile(text_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
